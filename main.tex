\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Report: Boosting Serverless Infrastructure with Swap and Fast Storage\\
% {\footnotesize \textsuperscript{*}Note: Sub-titles are not captured in Xplore and
% should not be used}
% \thanks{Identify applicable funding agency here. If none, delete this.}
}

\author{\IEEEauthorblockN{Hok Chun NG}
\IEEEauthorblockA{\textit{Department of Computer Science and Engineering} \\
\textit{Hong Kong University of Science and Technology}\\
Hong Kong, China \\
hcngac@connect.ust.hk}
% \and
% \IEEEauthorblockN{2\textsuperscript{nd} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{3\textsuperscript{rd} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{4\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{5\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
% \and
% \IEEEauthorblockN{6\textsuperscript{th} Given Name Surname}
% \IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
% \textit{name of organization (of Aff.)}\\
% City, Country \\
% email address or ORCID}
}

\maketitle

\begin{abstract}\label{abstract}
Serverless services, or Function-as-a-Service, provide users with the ability of executing functions on demand on the cloud without any operational effort of server and networking management. Cold start is a performance penalty situation where new execution instances of the serverless function has to be spawned to handle new incoming requests because there are no existing or available warm instances ready to be used. One mitigation is to pre-warm a number of instances such that there are always some free warm instances ready to use. This method however is limited on memory capacity and is not effective on scaling up. Swapping is one memory management technique where a persistent storage device is used to hold some unused memory content to free up physical memory space. Forking is a Linux system call where a process is copied to create a new process efficiently. We propose to use swap space on fast solid state storage devices to greatly increase pre-warmed instance count and to use swap and fork combined for a rapid response to surges in requests. Preliminary result shows a great potential for the swap method. We propose to use Knix as a base framework, where process forking is already used as rapid scaling method.
\end{abstract}

\begin{IEEEkeywords}
serverless, cold start, solid state storage
\end{IEEEkeywords}

\section{Introduction}
Serverless services provide cloud users the ability to quickly deploy a piece of code, usually in the form of a self-contained stateless function, without having to create or manage any physical or virtual machine. With the ease and speed of deploying with serverless, and the reasonable pricing scheme of paying for only the execution time of the function, serverless has become a very popular service in recent years. 

There are certain downsides to the serverless service, including the lack of permanent storage, lack of cooperation mechanism between execution instances and a slow cold-start and scale-up.

\subsection{Disecting the cold-start issue}
The problem of cold-start happens when a new function execution request comes in, but there are no free and ready function instances to immediately serve the request, and a new instance has to be created. Creating new instances involves two major steps: allocating or creating the environment for the instance (platform initialization) and function initialization. Platform initialization depends on the nature of the service framework. The environment can be a virtual machine, a container, or a plain process, depending on the requirements. VM provides the stronger hardware-based isolation between instances but with the heaviest setup, container provides a weaker operating system based isolation, and process have very little isolation with the fastest setup. Function initialization depends on the user code, including the coding language environment and imported libraries. 

\section{Literature Studies}

\subsection{Pre-warming}

\subsection{Pause Container Pool}
The main concept of the Pause Container Pool Management (PCPM) method is to create a pool of empty containers, ready for plugging in user functions. In some serverless framework, function instances are managed as containers. The creation of a new container involves a time cost, mainly in creating the networking stack of it. PCPM 

\subsection{Micro VM}

\section{Preliminary Result}

\subsection{Experiment Setup}

\subsection{Cold start time}

\subsection{Memory Consumption}

\section{Knix Framework Design}

We proposed to use Knix as a base for our swap trial. Knix is a workflow-based serverless platform, where a workflow is an execution unit and functions are organized in a workflow. In Knix a container is created for each workflow, and each function is executed in a process. This provides the fastest possible cold-start and scale-up time as the creation of new function instance utilizes Linux fork system call to lazy copy another complete and ready instance, skipping both environment and function initialization. 

Knix has two level of isolation: container-based isolation between workflows and process-based isolation between function instances. The stronger workflow isolation is for separating workflows possibly of different users. Functions within the same workflow are of the same user, so a weak process-level isolation suffices.

\subsection{Original Design}

In this section, we describes 

\subsubsection{Components}

\subsubsection{Request flow}

\subsection{Knix Structure}

\subsection{First Design}

\subsection{Second Design}

\end{document}
